{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nimbus_v1_tests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsnL358XRM77LFX+/VMGUK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDp7Vadvi77D"
      },
      "source": [
        "# D-Agostino's Test for Normality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMG5nOrAV33i"
      },
      "source": [
        "def d_agostino(df,fet):\n",
        "  from scipy.stats import normaltest\n",
        "  data=df[fet]\n",
        "  stat, p = normaltest(data)\n",
        "  alpha=float(input('ENTER THE P VALUE:'))\n",
        "  if p > alpha:\n",
        "    msg = 'Sample looks Gaussian (fail to reject H0)'\n",
        "  else:\n",
        "    msg = 'Sample does not look Gaussian (reject H0)'\n",
        "  #result_mat = [\n",
        "   #             ['Name of Test   ','Data Size    ','Test Statistic', 'p-value', 'Comments                  '],\n",
        "    #            [\"D'Agostino's\",len(data),stat,p,msg]\n",
        "     #           ]\n",
        "  #swt_table = ff.create_table(result_mat)\n",
        "  #swt_table['data'][0].colorscale=[[0, '#2a3f5f'],[1, '#ffffff']]\n",
        "  #swt_table['layout']['height']=200\n",
        "  #swt_table['layout']['margin']['t']=50\n",
        "  #swt_table['layout']['margin']['b']=50\n",
        "  #swt_table.show()\n",
        "  data={'NAME OF TEST':[\"D'Agostino's\"],\n",
        "        'DATA SIZE': [len(data)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "  df2=pd.DataFrame(data,columns=['NAME OF TEST','DATA SIZE','Test Statistic','p-value','Comments'])\n",
        "  df3=df2.T\n",
        "  display(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJsB6ZxAjFeA"
      },
      "source": [
        "\n",
        "# Anderson-Darling Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbpstcpNWI5K"
      },
      "source": [
        "def anderson_darling(df,fet):\n",
        "  import numpy as np\n",
        "  from scipy.stats import anderson\n",
        "  import plotly.figure_factory as ff\n",
        "  data=df[fet]\n",
        "  result = anderson(data)\n",
        "  stat = round(result.statistic, 4)\n",
        "  p = 0\n",
        "  result_mat = [['Name of Test','Length of data','Statistic','Significance Level','Critical Value','Comment']]\n",
        "  nam=[]\n",
        "  lent=[]\n",
        "  stats=[]\n",
        "  sig=[]\n",
        "  criv=[]\n",
        "  com=[]\n",
        "  for i in range(len(result.critical_values)):\n",
        "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
        "    if result.statistic < result.critical_values[i]:\n",
        "        msg = 'Sample looks Gaussian (fail to reject H0)'\n",
        "    else:\n",
        "        msg = 'Sample does not look Gaussian (reject H0)'\n",
        "    nam.append('ANDERSON-DARLING TEST')\n",
        "    lent.append(len(data))\n",
        "    stats.append(stat)\n",
        "    sig.append(sl)\n",
        "    criv.append(cv)\n",
        "    com.append(msg)\n",
        "    #result_mat.append(['Anderson-Darling',len(data), stat, sl, cv, msg])\n",
        "  #swt_table = ff.create_table(result_mat)\n",
        "  #swt_table['data'][0].colorscale=[[0, '#2a3f5f'],[1, '#ffffff']]\n",
        "  #swt_table['layout']['height']=200\n",
        "  #swt_table['layout']['margin']['t']=50\n",
        "  #swt_table['layout']['margin']['b']=50\n",
        "  #swt_table.show()\n",
        "  data={'NAME OF TEST':nam,\n",
        "        'DATA SIZE': lent,\n",
        "        'Test Statistic': stats,\n",
        "        'Significance Level':sig,\n",
        "        'Critical Value': criv,\n",
        "        'Comments': com}\n",
        "  df2=pd.DataFrame(data,columns=['NAME OF TEST','DATA SIZE','Test Statistic','Significance Level','Critical Value','Comments'])\n",
        "  #df3=df2.T\n",
        "  display(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0oqTdujLiK"
      },
      "source": [
        "# Shapiro Wilik Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1NeROQVWOXm"
      },
      "source": [
        "def shapiro_wilik(df,fet):\n",
        "  from scipy.stats import shapiro\n",
        "  data=df[fet]\n",
        "  stat,p=shapiro(data)\n",
        "  alpha=float(input('ENTER THE VALUE OF ALPHA:'))\n",
        "  if p > alpha:\n",
        "    msg = 'Sample looks Gaussian (fail to reject H0)'\n",
        "  else:\n",
        "    msg = 'Sample does not look Gaussian (reject H0)'\n",
        "  stat=round(stat,4)\n",
        "  p=round(p,4)\n",
        "  #result_mat = [\n",
        "               # ['Name of Test   ','Data Size    ','Test Statistic', 'p-value', 'Comments                  '],\n",
        "                #['Shapiro-Wilik',len(data),stat,p,msg]\n",
        "                #]\n",
        "  #swt_table = ff.create_table(result_mat)\n",
        "  #swt_table['data'][0].colorscale=[[0, '#2a3f5f'],[1, '#ffffff']]\n",
        "  #swt_table['layout']['height']=200\n",
        "  #swt_table['layout']['margin']['t']=50\n",
        "  #swt_table['layout']['margin']['b']=50\n",
        "  #swt_table.show()\n",
        "  data={'NAME OF TEST':['SHAPIRO WILIK'],\n",
        "        'DATA SIZE': [len(data)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "  df2=pd.DataFrame(data,columns=['NAME OF TEST','DATA SIZE','Test Statistic','p-value','Comments'])\n",
        "  df3=df2.T\n",
        "  display(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIIBBccYjP3_"
      },
      "source": [
        "# Q-Q Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fChtAGDfWXNf"
      },
      "source": [
        "def qq(df,fet):\n",
        "  import plotly\n",
        "  from statsmodels.graphics.gofplots import qqplot\n",
        "  import plotly.graph_objs as go\n",
        "  import plotly.figure_factory as ff\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import scipy\n",
        "  x=df[fet]\n",
        "  qqplot_data = qqplot(x, line='s').gca().lines\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace({\n",
        "      'type': 'scatter',\n",
        "      'x': qqplot_data[0].get_xdata(),\n",
        "      'y': qqplot_data[0].get_ydata(),\n",
        "      'mode': 'markers',\n",
        "      'marker': {\n",
        "          'color': '#19d3f3'}})\n",
        "  fig.add_trace({\n",
        "      'type': 'scatter',\n",
        "      'x': qqplot_data[1].get_xdata(),\n",
        "      'y': qqplot_data[1].get_ydata(),\n",
        "      'mode': 'lines',\n",
        "      'line': {\n",
        "          'color': '#636efa'\n",
        "      }\n",
        "\n",
        "  })\n",
        "\n",
        "\n",
        "  fig['layout'].update({\n",
        "      'title': 'Quantile-Quantile Plot',\n",
        "      'xaxis': {\n",
        "          'title': 'Theoritical Quantities',\n",
        "          'zeroline': False\n",
        "      },\n",
        "      'yaxis': {\n",
        "          'title': 'Sample Quantities'\n",
        "      },\n",
        "      'showlegend': False,\n",
        "      'width': 800,\n",
        "      'height': 700,\n",
        "  })\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61he5zbgmOFD"
      },
      "source": [
        "# Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drnFb5iBWafF"
      },
      "source": [
        "def histogram(df,fets):\n",
        "  import plotly.express as px\n",
        "  for fet in fets:\n",
        "    fig=px.histogram(df,x=fet)\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEAqSdGOmjsX"
      },
      "source": [
        "# Levine's Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odn47gq9f8Iu"
      },
      "source": [
        "def levine(df1,df2,fet1,fet2):\n",
        "  from scipy.stats import levene\n",
        "  data1=df1[fet1]\n",
        "  data2=df2[fet2]\n",
        "  stat, p = levene(data1,data2)\n",
        "  stat=round(stat,4)\n",
        "  alpha=0.05\n",
        "  if p > alpha:\n",
        "    msg = 'Input samples are from populations with equal variances (fail to reject H0)'\n",
        "  else:\n",
        "    msg = 'Input samples are from populations with equal variances (reject H0)'\n",
        "  #table(\"Levine's test\",len(data1),len(data2),stat,p,msg)\n",
        "  data={'NAME OF TEST':['Levine Test'],\n",
        "        'DATA 1 SIZE': [len(data1)],\n",
        "        'DATA 2 SIZE': [len(data2)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "  df3=pd.DataFrame(data,columns=['NAME OF TEST','DATA 1 SIZE','DATA 2 SIZE','Test Statistic','p-value','Comments'])\n",
        "  df4=df3.T\n",
        "  display(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brily9z-mnzk"
      },
      "source": [
        "# Fisher Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVO89pmYm7E2"
      },
      "source": [
        "def fisher_f(df1,df2,fet1,fet2):\n",
        "  import numpy as np\n",
        "  import scipy\n",
        "  data1=df1[fet1]\n",
        "  data2=df2[fet2]\n",
        "  stat= np.var(data1, ddof=1)/np.var(data2, ddof=1)\n",
        "  dfn = data1.size-1 #define degrees of freedom numerator \n",
        "  dfd = data2.size-1 #define degrees of freedom denominator\n",
        "  p = 1-scipy.stats.f.cdf(stat, dfn, dfd) #find p-value of F test statistic \n",
        "  stat=round(stat,4)\n",
        "  alpha=0.05\n",
        "  if p > alpha:\n",
        "    msg = 'Input samples are from populations with equal variances (fail to reject H0)'\n",
        "  else:\n",
        "    msg = 'Input samples are from populations with equal variances (reject H0)'\n",
        "  #table(\"FISHER'S F TEST\",len(data1),len(data2),stat,p,msg)\n",
        "  data={'NAME OF TEST':['Fisher F-Test'],\n",
        "        'DATA 1 SIZE': [len(data1)],\n",
        "        'DATA 2 SIZE': [len(data2)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "  df3=pd.DataFrame(data,columns=['NAME OF TEST','DATA 1 SIZE','DATA 2 SIZE','Test Statistic','p-value','Comments'])\n",
        "  df4=df3.T\n",
        "  display(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1_2Y0smtB5"
      },
      "source": [
        "# Chi Square Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfl9VK5AqXYx"
      },
      "source": [
        "# For categorical\n",
        "def chi_square_test(df,fet1,fet2):\n",
        "  from scipy.stats import chi2_contingency\n",
        "  from scipy.stats import chi2\n",
        "  unique_fet1=df[fet1].unique()\n",
        "  unique_fet2=df[fet2].unique()\n",
        "  table=list()\n",
        "  for i in unique_fet1:\n",
        "      rown=list()\n",
        "      for j in unique_fet2:\n",
        "          rown.append(len(df[(df[fet1]==i)&(df[fet2]==j)]))\n",
        "      table.append(rown)\n",
        "  stat,p,dof,expected=chi2_contingency(table)\n",
        "  #print('DEGREES OF FREEDOM:%d' %dof)\n",
        "  #print('EXPECTED:')\n",
        "  #print(expected)\n",
        "  prob=float(input('ENTER A PROBABILITY VALUE (BETWEEN 0 TO 1):'))\n",
        "  critical=chi2.ppf(prob,dof)\n",
        "  #print('PROBABILITY:%.3f' %(prob))\n",
        "  #print('CRITICAL VALUE:%.3f' %(critical))\n",
        "  #print('STATISTIC:%.3f' %(stat))\n",
        "  if (abs(stat)>=critical):\n",
        "      msg='DEPENDENT (REJECT NULL HYPOTHESIS).'\n",
        "  else:\n",
        "      msg='INDEPENDENT ( FAIL TO REJECT NULL HYPOTHESIS).'\n",
        "  data={'NAME OF TEST':['Chi-Square Test'],\n",
        "        'DATA SIZE': [len(df[fet1])],\n",
        "        'DEEGREES OF FREEDOM':dof,\n",
        "       # 'EXPECTED':expected,\n",
        "        'Test Statistic': [stat],\n",
        "        'Critical value': [critical],\n",
        "        'Probability Value Inputted':prob,\n",
        "        'Comments': [msg]}\n",
        "  df2=pd.DataFrame(data,columns=['NAME OF TEST','DATA SIZE','DEEGREES OF FREEDOM','Test Statistic','Critical value','Probability Value Inputted','Comments'])\n",
        "  df3=df2.T\n",
        "  display(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajw5N6HyqZBk"
      },
      "source": [
        "# Independent T-Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q2MUpI-wkjS"
      },
      "source": [
        "def independent_t_test(df1,df2,fet1,fet2):\n",
        "    from scipy.stats import ttest_ind\n",
        "    data1=df1[fet1]\n",
        "    data2=df2[fet2]\n",
        "    stat,p=ttest_ind(data1, data2)\n",
        "    alpha=float(input('ENTER P VALUE FOR HYPOTHESIS TESTING:'))\n",
        "    if (p>alpha):\n",
        "      msg='SAME DISTRIBUTIONS (FAIL TO REJECT NULL HYPOTHESIS).'\n",
        "    else:\n",
        "      msg='DIFFERENT DISTRIBUTIONS (REJECT NULL HYPOTHESIS).'\n",
        "    #table('INDEPENDENT T',len(data1),len(data2),stat,p,msg)\n",
        "    data={'NAME OF TEST':['INDEPENDENT T-Test'],\n",
        "        'DATA 1 SIZE': [len(data1)],\n",
        "        'DATA 2 SIZE': [len(data2)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "    df3=pd.DataFrame(data,columns=['NAME OF TEST','DATA 1 SIZE','DATA 2 SIZE','Test Statistic','p-value','Comments'])\n",
        "    df4=df3.T\n",
        "    display(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBv0mro_02xe"
      },
      "source": [
        "# One Way ANOVA (3 datasets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLpXh5Yc07qO"
      },
      "source": [
        "def one_way_anova_3(df1,df2,df3,fet1,fet2,fet3):\n",
        "    from scipy.stats import f_oneway\n",
        "    data1=df1[fet1]\n",
        "    data2=df2[fet2]\n",
        "    data3=df1[fet3]\n",
        "    stat,p=f_oneway(data1,data2,data3)\n",
        "    # ADD MORE IF NEEDED\n",
        "    alpha=float(input('ENTER P VALUE FOR HYPOTHESIS TESTING:'))\n",
        "    if (p>alpha):\n",
        "      msg='SAME DISTRIBUTIONS (FAIL TO REJECT NULL HYPOTHESIS).'\n",
        "    else:\n",
        "      msg='DIFFERENT DISTRIBUTIONS (REJECT NULL HYPOTHESIS).'\n",
        "    # tablebig('One Way ANOVA',len(data1),len(data2),len(data3),stat,p,msg)\n",
        "    data={'NAME OF TEST':['INDEPENDENT T-Test'],\n",
        "        'DATA 1 SIZE': [len(data1)],\n",
        "        'DATA 2 SIZE': [len(data2)],\n",
        "        'DATA 3 SIZE': [len(data3)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "    df4=pd.DataFrame(data,columns=['NAME OF TEST','DATA 1 SIZE','DATA 2 SIZE','DATA 3 SIZE','Test Statistic','p-value','Comments'])\n",
        "    df5=df4.T\n",
        "    display(df5)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg0N4f321ETk"
      },
      "source": [
        "# One Way ANOVA (2 datasets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9G_z0S1NUn"
      },
      "source": [
        "def one_way_anova_2(df1,df2,fet1,fet2):\n",
        "    from scipy.stats import f_oneway\n",
        "    data1=df1[fet1]\n",
        "    data2=df2[fet2]\n",
        "    # data3=df1[fet3]\n",
        "    stat,p=f_oneway(data1,data2)\n",
        "    # ADD MORE IF NEEDED\n",
        "    alpha=float(input('ENTER P VALUE FOR HYPOTHESIS TESTING:'))\n",
        "    if (p>alpha):\n",
        "      msg='SAME DISTRIBUTIONS (FAIL TO REJECT NULL HYPOTHESIS).'\n",
        "    else:\n",
        "      msg='DIFFERENT DISTRIBUTIONS (REJECT NULL HYPOTHESIS).'\n",
        "    # tablebig('One Way ANOVA',len(data1),len(data2),len(data3),stat,p,msg)\n",
        "    data={'NAME OF TEST':['INDEPENDENT T-Test'],\n",
        "        'DATA 1 SIZE': [len(data1)],\n",
        "        'DATA 2 SIZE': [len(data2)],\n",
        "        #'DATA 2 SIZE': [len(data3)],\n",
        "        'Test Statistic': [stat],\n",
        "        'p-value': [p],\n",
        "        'Comments': [msg]}\n",
        "    df4=pd.DataFrame(data,columns=['NAME OF TEST','DATA 1 SIZE','DATA 2 SIZE','Test Statistic','p-value','Comments'])\n",
        "    df5=df4.T\n",
        "    display(df5)"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}